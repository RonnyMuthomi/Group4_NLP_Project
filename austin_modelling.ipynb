{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb76325b",
   "metadata": {},
   "source": [
    "# Modelling Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a680909",
   "metadata": {},
   "source": [
    "## 1. Data Loading and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b639837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...</td>\n",
       "      <td>g iphon hr tweet dead need upgrad plugin station</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['know', 'awesom', 'ipadiphon', 'app', 'youll'...</td>\n",
       "      <td>know awesom ipadiphon app youll like appreci d...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>['wait', 'also', 'sale']</td>\n",
       "      <td>wait also sale</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['hope', 'year', 'festiv', 'isnt', 'crashi', '...</td>\n",
       "      <td>hope year festiv isnt crashi year iphon app</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>['great', 'stuff', 'fri', 'marissa', 'mayer', ...</td>\n",
       "      <td>great stuff fri marissa mayer googl tim oreill...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...   \n",
       "1  ['know', 'awesom', 'ipadiphon', 'app', 'youll'...   \n",
       "2                           ['wait', 'also', 'sale']   \n",
       "3  ['hope', 'year', 'festiv', 'isnt', 'crashi', '...   \n",
       "4  ['great', 'stuff', 'fri', 'marissa', 'mayer', ...   \n",
       "\n",
       "                                     processed_tweet         sentiment  \n",
       "0   g iphon hr tweet dead need upgrad plugin station  Negative emotion  \n",
       "1  know awesom ipadiphon app youll like appreci d...  Positive emotion  \n",
       "2                                     wait also sale  Positive emotion  \n",
       "3        hope year festiv isnt crashi year iphon app  Negative emotion  \n",
       "4  great stuff fri marissa mayer googl tim oreill...  Positive emotion  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_cleaned_df = pd.read_csv('data/cleaned_apple_tweets.csv')\n",
    "tweets_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17518e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5375\n",
       "Positive emotion                      2970\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_cleaned_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4540d8",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2f8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned_df = tweets_cleaned_df.dropna(subset=['processed_tweet', 'sentiment'])  # Removes rows where text or label is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dee09",
   "metadata": {},
   "source": [
    "# Train_Test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbeb4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_cleaned_df['processed_tweet']\n",
    "y = tweets_cleaned_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce0a30",
   "metadata": {},
   "source": [
    "# Building the pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b34142",
   "metadata": {},
   "source": [
    "### Import Necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ab94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe10f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf' , TfidfVectorizer(stop_words ='english')), \n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7953d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924cd795",
   "metadata": {},
   "source": [
    "# Predict and Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "137caf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 68.58%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9edb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
