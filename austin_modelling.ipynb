{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb76325b",
   "metadata": {},
   "source": [
    "# Modelling Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a680909",
   "metadata": {},
   "source": [
    "## 1. Data Loading and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b639837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...</td>\n",
       "      <td>g iphon hr tweet dead need upgrad plugin station</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['know', 'awesom', 'ipadiphon', 'app', 'youll'...</td>\n",
       "      <td>know awesom ipadiphon app youll like appreci d...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>['wait', 'also', 'sale']</td>\n",
       "      <td>wait also sale</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['hope', 'year', 'festiv', 'isnt', 'crashi', '...</td>\n",
       "      <td>hope year festiv isnt crashi year iphon app</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>['great', 'stuff', 'fri', 'marissa', 'mayer', ...</td>\n",
       "      <td>great stuff fri marissa mayer googl tim oreill...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...   \n",
       "1  ['know', 'awesom', 'ipadiphon', 'app', 'youll'...   \n",
       "2                           ['wait', 'also', 'sale']   \n",
       "3  ['hope', 'year', 'festiv', 'isnt', 'crashi', '...   \n",
       "4  ['great', 'stuff', 'fri', 'marissa', 'mayer', ...   \n",
       "\n",
       "                                     processed_tweet         sentiment  \n",
       "0   g iphon hr tweet dead need upgrad plugin station  Negative emotion  \n",
       "1  know awesom ipadiphon app youll like appreci d...  Positive emotion  \n",
       "2                                     wait also sale  Positive emotion  \n",
       "3        hope year festiv isnt crashi year iphon app  Negative emotion  \n",
       "4  great stuff fri marissa mayer googl tim oreill...  Positive emotion  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_cleaned_df = pd.read_csv('data/cleaned_apple_tweets.csv')\n",
    "tweets_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17518e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5375\n",
       "Positive emotion                      2970\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_cleaned_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4540d8",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b2f8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned_df = tweets_cleaned_df.dropna(subset=['processed_tweet', 'sentiment'])  # Removes rows where text or label is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dee09",
   "metadata": {},
   "source": [
    "# Train_Test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbeb4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_cleaned_df['processed_tweet']\n",
    "y = tweets_cleaned_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce0a30",
   "metadata": {},
   "source": [
    "# Building the pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b34142",
   "metadata": {},
   "source": [
    "### Import Necessary libraries to make sure all tools are available.because we are interested in creating a **pipeline structure** that is streamlined and modulates the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60ab94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee349111",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe10f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf' , TfidfVectorizer(stop_words ='english')), \n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7953d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924cd795",
   "metadata": {},
   "source": [
    "# Predict and Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "137caf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 68.58%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493bf649",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with GridSearchCV \n",
    "### We need to find the best parameters for our model inorder to evaluate its performance.With a **68%** baseline ,grid search will help uncover the optimal combination of `vectorizartion` and `logistic regression` parameters.\n",
    "### And finally get accurate predictions inorder to push our `accuracy` higher.\n",
    "\n",
    "## Tuning of :\n",
    "1. `max_df` :ignoring the wording that appear in too many documents.\n",
    "2. `ngram_range` :Unigrams vs bigrams \n",
    "3. `C` :Regularization strength of logistic regression.\n",
    "\n",
    "### This is to explore combination of texts features granularity and the model flexibility ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1c0bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV    \n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.8, 0.9, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'classifier__C': [0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2730f",
   "metadata": {},
   "source": [
    "## Setting up Grid Search \n",
    "### `cv=5` applies 5 -fold **cross validation**. in `verbose=1` shows progress,`n_jobs= -1` uses cores to speed it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f1fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   42.3s finished\n",
      "c:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [0.1, 1, 10],\n",
       "                         'tfidf__max_df': [0.8, 0.9, 1.0],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633741d",
   "metadata": {},
   "source": [
    "## Evaluate the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af9ca48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__C': 1, 'tfidf__max_df': 0.8, 'tfidf__ngram_range': (1, 2)}\n",
      "Accuracy: 0.6984564498346196\n",
      "Classification Report:\n",
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                      I can't tell       0.00      0.00      0.00        27\n",
      "                  Negative emotion       0.78      0.06      0.11       124\n",
      "No emotion toward brand or product       0.71      0.89      0.79      1091\n",
      "                  Positive emotion       0.65      0.51      0.57       572\n",
      "\n",
      "                          accuracy                           0.70      1814\n",
      "                         macro avg       0.54      0.36      0.37      1814\n",
      "                      weighted avg       0.69      0.70      0.66      1814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44d10d",
   "metadata": {},
   "source": [
    "# Computing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df11924",
   "metadata": {},
   "source": [
    "### Computing a confucion matrix to give a breakdown of how well our model is classifying each **sentiment class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f9edb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  0   0  19   8]\n",
      " [  0   7  90  27]\n",
      " [  0   2 969 120]\n",
      " [  0   0 281 291]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#predict labels \n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "#create matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1807f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
