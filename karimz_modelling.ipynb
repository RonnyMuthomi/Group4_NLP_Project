{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93dedf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "import os\n",
    "from typing import Tuple, Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a728073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...</td>\n",
       "      <td>g iphon hr tweet dead need upgrad plugin station</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['know', 'awesom', 'ipadiphon', 'app', 'youll'...</td>\n",
       "      <td>know awesom ipadiphon app youll like appreci d...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>['wait', 'also', 'sale']</td>\n",
       "      <td>wait also sale</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>['hope', 'year', 'festiv', 'isnt', 'crashi', '...</td>\n",
       "      <td>hope year festiv isnt crashi year iphon app</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>['great', 'stuff', 'fri', 'marissa', 'mayer', ...</td>\n",
       "      <td>great stuff fri marissa mayer googl tim oreill...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['g', 'iphon', 'hr', 'tweet', 'dead', 'need', ...   \n",
       "1  ['know', 'awesom', 'ipadiphon', 'app', 'youll'...   \n",
       "2                           ['wait', 'also', 'sale']   \n",
       "3  ['hope', 'year', 'festiv', 'isnt', 'crashi', '...   \n",
       "4  ['great', 'stuff', 'fri', 'marissa', 'mayer', ...   \n",
       "\n",
       "                                     processed_tweet         sentiment  \n",
       "0   g iphon hr tweet dead need upgrad plugin station  Negative emotion  \n",
       "1  know awesom ipadiphon app youll like appreci d...  Positive emotion  \n",
       "2                                     wait also sale  Positive emotion  \n",
       "3        hope year festiv isnt crashi year iphon app  Negative emotion  \n",
       "4  great stuff fri marissa mayer googl tim oreill...  Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "cleaned_tweets_df = pd.read_csv('data/cleaned_apple_tweets.csv')\n",
    "cleaned_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d283f",
   "metadata": {},
   "source": [
    "# Base Data Processor Class\n",
    "\n",
    "This module provides a base class for data preprocessing operations with the following functionality:\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Data Loading**: Supports loading data from either a file path or an existing DataFrame\n",
    "- **Basic Preprocessing**:\n",
    "  - Handles missing values in key columns\n",
    "  - Cleans string labels by stripping whitespace\n",
    "- **Label Encoding**:\n",
    "  - Converts string labels to numeric values\n",
    "  - Provides mapping between numeric labels and original string labels\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "The `BaseDataProcessor` class serves as a foundation for more specialized data processing implementations. It includes:\n",
    "- A LabelEncoder for converting string labels to numeric values\n",
    "- Placeholder for a vectorizer (to be implemented in subclasses)\n",
    "- Tracking of feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beee963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataProcessor:\n",
    "    \"\"\"Base class for data preprocessing operations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.vectorizer = None\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def load_data(self, data_path: str = None, data_df: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"Load data from file or dataframe\"\"\"\n",
    "        if data_df is not None:\n",
    "            return data_df\n",
    "        elif data_path is not None:\n",
    "            return pd.read_csv(data_path)\n",
    "        else:\n",
    "            raise ValueError(\"Either data_path or data_df must be provided\")\n",
    "    \n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Basic preprocessing steps\"\"\"\n",
    "        # Handle missing values\n",
    "        df = df.dropna(subset=['processed_tweet', 'sentiment'])\n",
    "        \n",
    "        # Clean sentiment labels\n",
    "        df['sentiment'] = df['sentiment'].str.strip()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def encode_labels(self, y: pd.Series) -> np.ndarray:\n",
    "        \"\"\"Encode string labels to numeric\"\"\"\n",
    "        return self.label_encoder.fit_transform(y)\n",
    "    \n",
    "    def get_label_mapping(self) -> Dict[int, str]:\n",
    "        \"\"\"Get mapping from numeric labels to string labels\"\"\"\n",
    "        return {i: label for i, label in enumerate(self.label_encoder.classes_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccabbe9",
   "metadata": {},
   "source": [
    "# Feature Extractor Class\n",
    "\n",
    "Extends `BaseDataProcessor` to handle text feature extraction using different vectorization techniques.\n",
    "\n",
    "## Key Functionality\n",
    "\n",
    "- **Vectorizer Configuration**: Supports both TF-IDF and Count Vectorizer methods\n",
    "- **Feature Transformation**: Converts text data into numerical features\n",
    "- **Feature Analysis**: Provides feature importance extraction for model interpretation\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "### Vectorizer Types\n",
    "1. **TF-IDF** (`vectorizer_type='tfidf'`)\n",
    "   - Default option with unigram features\n",
    "   - Removes stopwords and converts to lowercase\n",
    "2. **Count Vectorizer** (`vectorizer_type='count'`)\n",
    "   - Includes both unigrams and bigrams\n",
    "   - Same text normalization as TF-IDF\n",
    "\n",
    "### Parameters\n",
    "- `max_features`: Controls vocabulary size (default: 1000)\n",
    "- `ngram_range`:\n",
    "  - (1,1) for TF-IDF (unigrams only)\n",
    "  - (1,2) for Count Vectorizer (unigrams + bigrams)\n",
    "\n",
    "## Core Methods\n",
    "\n",
    "### `fit_transform_features`\n",
    "- Transforms text data into feature matrices\n",
    "- Handles both training and test data with proper feature alignment\n",
    "- Stores feature names for reference\n",
    "\n",
    "### `get_feature_importance`\n",
    "- Works with:\n",
    "  - Tree-based models (using `feature_importances_`)\n",
    "  - Linear models (using absolute coefficients)\n",
    "- Returns ranked features DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ae1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseDataProcessor):\n",
    "    \"\"\"Class for extracting features from text data\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorizer_type: str = 'tfidf', max_features: int = 1000):\n",
    "        super().__init__()\n",
    "        self.vectorizer_type = vectorizer_type\n",
    "        self.max_features = max_features\n",
    "        self._initialize_vectorizer()\n",
    "    \n",
    "    def _initialize_vectorizer(self):\n",
    "        \"\"\"Initialize the appropriate vectorizer\"\"\"\n",
    "        if self.vectorizer_type == 'tfidf':\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=self.max_features,\n",
    "                stop_words='english',\n",
    "                lowercase=True,\n",
    "                ngram_range=(1, 1)\n",
    "            )\n",
    "        elif self.vectorizer_type == 'count':\n",
    "            self.vectorizer = CountVectorizer(\n",
    "                max_features=self.max_features,\n",
    "                stop_words='english',\n",
    "                lowercase=True,\n",
    "                ngram_range=(1, 2)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"vectorizer_type must be 'tfidf' or 'count'\")\n",
    "    \n",
    "    def fit_transform_features(self, X_train: pd.Series, X_test: pd.Series = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Fit vectorizer on training data and transform both train and test\"\"\"\n",
    "        X_train_vec = self.vectorizer.fit_transform(X_train)\n",
    "        self.feature_names = self.vectorizer.get_feature_names()\n",
    "        \n",
    "        if X_test is not None:\n",
    "            X_test_vec = self.vectorizer.transform(X_test)\n",
    "            return X_train_vec.toarray(), X_test_vec.toarray()\n",
    "        \n",
    "        return X_train_vec.toarray(), None\n",
    "    \n",
    "    def get_feature_importance(self, model, top_n: int = 20) -> pd.DataFrame:\n",
    "        \"\"\"Get feature importance for models that support it\"\"\"\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importance = np.abs(model.coef_).mean(axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"Model doesn't have feature importance or coefficients\")\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return feature_importance.head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835963fc",
   "metadata": {},
   "source": [
    "# Data Splitter Class\n",
    "\n",
    "Handles stratified splitting of datasets into train, validation, and test sets with reproducible randomization.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Stratified Splitting**: Maintains original class distribution in all splits\n",
    "- **Flexible Sizing**: Configurable test and validation set sizes\n",
    "- **Reproducibility**: Fixed random state for consistent results across runs\n",
    "\n",
    "## Splitting Strategy\n",
    "\n",
    "1. **First Split**:\n",
    "   - Separates test set from the full dataset (`test_size`)\n",
    "   - Remaining data kept for training+validation\n",
    "\n",
    "2. **Second Split**:\n",
    "   - Divides the remaining data into training and validation sets\n",
    "   - Automatically adjusts validation size relative to remaining data\n",
    "\n",
    "```python\n",
    "# Visual representation of the splitting logic\n",
    "Full Dataset\n",
    "├── Test Set (20%)\n",
    "└── Training+Validation (80%)\n",
    "    ├── Training Set (64%)\n",
    "    └── Validation Set (16%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4d509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitter:\n",
    "    \"\"\"Class for splitting data into train/validation/test sets\"\"\"\n",
    "    \n",
    "    def __init__(self, test_size: float = 0.2, val_size: float = 0.2, random_state: int = 42):\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def split_data(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Split data into train, validation, and test sets\"\"\"\n",
    "        # First split: train+val vs test\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Second split: train vs val\n",
    "        val_size_adjusted = self.val_size / (1 - self.test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size_adjusted, random_state=self.random_state, stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7061edd",
   "metadata": {},
   "source": [
    "# Model Evaluator Class\n",
    "\n",
    "Provides comprehensive model evaluation capabilities including metrics calculation, visualization, and model comparison.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Multi-metric Evaluation**: Computes accuracy, classification report, and confusion matrix\n",
    "- **Results Tracking**: Stores evaluation results for multiple models\n",
    "- **Visualization**: Includes built-in plotting functions\n",
    "- **Model Comparison**: Quantitative and visual comparison of model performance\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "| Metric | Description | Output Format |\n",
    "|--------|-------------|---------------|\n",
    "| Accuracy | Overall classification accuracy | float (0-1) |\n",
    "| Classification Report | Precision, recall, f1-score per class | sklearn string report |\n",
    "| Confusion Matrix | Class-wise prediction counts | 2D numpy array |\n",
    "| Predictions | Raw model predictions | numpy array |\n",
    "\n",
    "## Core Methods\n",
    "\n",
    "### `evaluate_model`\n",
    "```python\n",
    "evaluate_model(model, X_test, y_test, model_name) -> dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c8a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Class for evaluating model performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def evaluate_model(self, model, X_test: np.ndarray, y_test: np.ndarray, model_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'classification_report': classification_report(y_test, y_pred),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        self.results[model_name] = results\n",
    "        return results\n",
    "    \n",
    "    def plot_confusion_matrix(self, model_name: str, labels: List[str] = None):\n",
    "        \"\"\"Plot confusion matrix for a model\"\"\"\n",
    "        if model_name not in self.results:\n",
    "            raise ValueError(f\"Model {model_name} not found in results\")\n",
    "        \n",
    "        cm = self.results[model_name]['confusion_matrix']\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=labels, yticklabels=labels)\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def compare_models(self) -> pd.DataFrame:\n",
    "        \"\"\"Compare accuracy of all evaluated models\"\"\"\n",
    "        comparison = pd.DataFrame([\n",
    "            {'Model': name, 'Accuracy': results['accuracy']}\n",
    "            for name, results in self.results.items()\n",
    "        ]).sort_values('Accuracy', ascending=False)\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def plot_model_comparison(self):\n",
    "        \"\"\"Plot comparison of model accuracies\"\"\"\n",
    "        comparison = self.compare_models()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(comparison['Model'], comparison['Accuracy'])\n",
    "        plt.title('Model Accuracy Comparison')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, acc in zip(bars, comparison['Accuracy']):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                    f'{acc:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7626277",
   "metadata": {},
   "source": [
    "# Implementation Testing\n",
    "\n",
    "This section demonstrates the usage of the base classes through a practical test script.\n",
    "\n",
    "## Test Script Overview\n",
    "\n",
    "The script verifies:\n",
    "1. Data preprocessing pipeline\n",
    "2. Label encoding functionality\n",
    "3. Feature extraction capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e8815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing test:\n",
      "Original shape: (9070, 5)\n",
      "Clean shape: (9068, 5)\n",
      "Label mapping: {0: \"I can't tell\", 1: 'Negative emotion', 2: 'No emotion toward brand or product', 3: 'Positive emotion'}\n",
      "Encoded labels: [1 3 3 ... 2 2 2]\n",
      "\n",
      "Feature extraction test:\n",
      "Feature matrix shape: (9068, 100)\n",
      "Number of features: 100\n",
      "\n",
      "Base classes setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Usage and testing\n",
    "if __name__ == \"__main__\": \n",
    "    # Test the base classes\n",
    "    df = cleaned_tweets_df\n",
    "    \n",
    "    # Test data processor\n",
    "    processor = BaseDataProcessor()\n",
    "    df_clean = processor.preprocess_data(df)\n",
    "    y_encoded = processor.encode_labels(df_clean['sentiment'])\n",
    "    label_mapping = processor.get_label_mapping()\n",
    "    \n",
    "    print(\"Data processing test:\")\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"Clean shape: {df_clean.shape}\")\n",
    "    print(f\"Label mapping: {label_mapping}\")\n",
    "    print(f\"Encoded labels: {y_encoded}\")\n",
    "    \n",
    "    # Test feature extractor\n",
    "    feature_extractor = FeatureExtractor(vectorizer_type='tfidf', max_features=100)\n",
    "    X_train, _ = feature_extractor.fit_transform_features(df_clean['processed_tweet'])\n",
    "    \n",
    "    print(f\"\\nFeature extraction test:\")\n",
    "    print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "    print(f\"Number of features: {len(feature_extractor.feature_names)}\")\n",
    "    \n",
    "    print(\"\\nBase classes setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcb589",
   "metadata": {},
   "source": [
    "# Base Sentiment Classifier (ABC)\n",
    "\n",
    "Abstract base class defining the interface and common functionality for all sentiment classification models.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Core Responsibilities\n",
    "- Standardizes model initialization and training\n",
    "- Provides common evaluation methods\n",
    "- Implements hyperparameter tuning workflow\n",
    "- Handles model serialization\n",
    "\n",
    "### Key Features\n",
    "- **Abstract Methods**: Requires concrete implementations for model-specific logic\n",
    "- **State Tracking**: Maintains model fitting status\n",
    "- **Hyperparameter Management**: Supports grid search tuning\n",
    "- **Cross-Validation**: Built-in performance evaluation\n",
    "- **Model Persistence**: Save/load functionality\n",
    "\n",
    "## Abstract Methods\n",
    "\n",
    "| Method | Description | Returns |\n",
    "|--------|-------------|---------|\n",
    "| `_initialize_model()` | Creates model instance | Model object |\n",
    "| `get_hyperparameters()` | Defines parameter grid for tuning | Dictionary of parameter lists |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc4e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSentimentClassifier(ABC):\n",
    "    \"\"\"Abstract base class for sentiment classification models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.is_fitted = False\n",
    "        self.best_params = None\n",
    "        self.cv_scores = None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _initialize_model(self) -> Any:\n",
    "        \"\"\"Initialize the specific model\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get hyperparameters for grid search\"\"\"\n",
    "        return {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear'],\n",
    "            'penalty': ['l2']\n",
    "        }\n",
    "    \n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        \"\"\"Fit the model\"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = self._initialize_model()\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Get prediction probabilities\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def hyperparameter_tuning(self, X_train: np.ndarray, y_train: np.ndarray, \n",
    "                            cv: int = 3, scoring: str = 'accuracy') -> Dict[str, Any]:\n",
    "        \"\"\"Perform hyperparameter tuning using GridSearchCV\"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = self._initialize_model()\n",
    "        \n",
    "        param_grid = self.get_hyperparameters()\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            self.model, param_grid, cv=cv, scoring=scoring, \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        self.model = grid_search.best_estimator_\n",
    "        self.best_params = grid_search.best_params_\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return {\n",
    "            'best_params': self.best_params,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'cv_results': grid_search.cv_results_\n",
    "        }\n",
    "    \n",
    "    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\n",
    "        \"\"\"Perform cross-validation\"\"\"\n",
    "        if self.model is None:\n",
    "            self.model = self._initialize_model()\n",
    "        \n",
    "        scores = cross_val_score(self.model, X, y, cv=cv, scoring='accuracy')\n",
    "        self.cv_scores = scores\n",
    "        \n",
    "        return {\n",
    "            'mean_score': scores.mean(),\n",
    "            'std_score': scores.std(),\n",
    "            'scores': scores\n",
    "        }\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before saving\")\n",
    "        \n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'model_name': self.model_name,\n",
    "            'best_params': self.best_params\n",
    "        }, filepath)\n",
    "    \n",
    "    def load_model(self, filepath: str):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        data = joblib.load(filepath)\n",
    "        self.model = data['model']\n",
    "        self.model_name = data['model_name']\n",
    "        self.best_params = data.get('best_params', None)\n",
    "        self.is_fitted = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c8302",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier\n",
    "\n",
    "Concrete implementation of `BaseSentimentClassifier` for logistic regression-based sentiment analysis.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier`\n",
    "- Implements all required abstract methods\n",
    "- Adds logistic regression-specific configuration\n",
    "\n",
    "### Key Features\n",
    "- Configurable random state for reproducibility\n",
    "- Optimized for sentiment analysis (multi-class)\n",
    "- Comprehensive hyperparameter grid for tuning\n",
    "- Standard scikit-learn estimator interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7810c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Logistic Regression classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"Logistic Regression\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> LogisticRegression:\n",
    "        return LogisticRegression(\n",
    "            random_state=self.random_state,\n",
    "            max_iter=1000,\n",
    "            multi_class='ovr'\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear', 'lbfgs'],\n",
    "            'penalty': ['l1', 'l2']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00aaf8",
   "metadata": {},
   "source": [
    "# Random Forest Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using Random Forest for sentiment analysis tasks.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures Random Forest-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Parallelized training (`n_jobs=-1`)\n",
    "- Comprehensive hyperparameter tuning grid\n",
    "- Built-in feature importance analysis\n",
    "- Handles class imbalance through weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0aa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Random Forest classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"Random Forest\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> RandomForestClassifier:\n",
    "        return RandomForestClassifier(\n",
    "            random_state=self.random_state,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064164a",
   "metadata": {},
   "source": [
    "# Decision Tree Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using a Decision Tree algorithm for sentiment analysis.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures Decision Tree-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Interpretable model structure\n",
    "- Configurable splitting criteria\n",
    "- Pruning controls to prevent overfitting\n",
    "- Feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1856d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Decision Tree classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"Decision Tree\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> DecisionTreeClassifier:\n",
    "        return DecisionTreeClassifier(\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'max_depth': [5, 10, 15, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],  \n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7cf62",
   "metadata": {},
   "source": [
    "# Gradient Boosting Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using Gradient Boosting Machines (GBM) for sentiment analysis.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures GBM-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Sequential ensemble of decision trees\n",
    "- Adaptive boosting (AdaBoost) mechanism\n",
    "- Configurable learning rate\n",
    "- Built-in feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea0c137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Gradient Boosting classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"Gradient Boosting\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> GradientBoostingClassifier:\n",
    "        return GradientBoostingClassifier(\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773133c8",
   "metadata": {},
   "source": [
    "# XGBoost Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using XGBoost (Extreme Gradient Boosting) for sentiment analysis.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures XGBoost-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Optimized gradient boosting implementation\n",
    "- Built-in regularization to prevent overfitting\n",
    "- Parallel processing support\n",
    "- Advanced features for handling imbalanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5a69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"XGBoost classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"XGBoost\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> Any:\n",
    "        import xgboost as xgb\n",
    "        return xgb.XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.8, 1.0]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0aa72",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using K-Nearest Neighbors algorithm for sentiment analysis.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures KNN-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Instance-based learning (no explicit training)\n",
    "- Flexible distance metrics\n",
    "- Weighted voting options\n",
    "- Naturally handles multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08931c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"K-Nearest Neighbors classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"K-Nearest Neighbors\")\n",
    "    \n",
    "    def _initialize_model(self) -> KNeighborsClassifier:\n",
    "        return KNeighborsClassifier()\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbbaa6",
   "metadata": {},
   "source": [
    "# Naive Bayes Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using Multinomial Naive Bayes for sentiment analysis, particularly effective for text classification tasks.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures Naive Bayes-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Extremely fast training and prediction\n",
    "- Naturally handles multi-class classification\n",
    "- Works well with text frequency features\n",
    "- Low memory footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22656db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Naive Bayes classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"Naive Bayes\")\n",
    "    \n",
    "    def _initialize_model(self) -> MultinomialNB:\n",
    "        return MultinomialNB()\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'alpha': [0.1, 0.5, 1.0, 2.0],\n",
    "            'fit_prior': [True, False]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76c747",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using a neural network (MLP) for sentiment analysis, capable of learning complex patterns in text data.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures neural network-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Feedforward artificial neural network\n",
    "- Automatic validation set for early stopping\n",
    "- Multiple activation function options\n",
    "- Adaptive learning rate capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5099d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"Multi-layer Perceptron classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"Neural Network (MLP)\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> MLPClassifier:\n",
    "        return MLPClassifier(\n",
    "            random_state=self.random_state,\n",
    "            max_iter=1000,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate': ['constant', 'adaptive']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ead9c",
   "metadata": {},
   "source": [
    "# AdaBoost Sentiment Classifier\n",
    "\n",
    "Implementation of `BaseSentimentClassifier` using Adaptive Boosting (AdaBoost) for sentiment analysis, particularly effective for improving weak classifiers.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Inheritance\n",
    "- Extends `BaseSentimentClassifier` abstract class\n",
    "- Implements all required abstract methods\n",
    "- Configures AdaBoost-specific parameters\n",
    "\n",
    "### Key Features\n",
    "- Sequential ensemble that corrects previous mistakes\n",
    "- Can use various base estimators (default: Decision Stump)\n",
    "- Handles both binary and multi-class classification\n",
    "- Naturally addresses class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90fbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostSentimentClassifier(BaseSentimentClassifier):\n",
    "    \"\"\"AdaBoost classifier for sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = 42):\n",
    "        super().__init__(\"AdaBoost\")\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _initialize_model(self) -> AdaBoostClassifier:\n",
    "        return AdaBoostClassifier(\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "    \n",
    "    def get_hyperparameters(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.5, 1.0, 1.5],\n",
    "            'algorithm': ['SAMME', 'SAMME.R']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a64f3d",
   "metadata": {},
   "source": [
    "# Model Manager\n",
    "\n",
    "Centralized management system for handling multiple sentiment classification models, enabling streamlined training, evaluation, and comparison.\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "### Core Responsibilities\n",
    "- Unified interface for multiple classifier types\n",
    "- Batch training and evaluation\n",
    "- Model persistence management\n",
    "- Performance comparison\n",
    "\n",
    "### Key Features\n",
    "- Supports all implemented classifier types\n",
    "- Optional hyperparameter tuning\n",
    "- Cross-validation during training\n",
    "- Model serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb98c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification models setup complete!\n",
      "\n",
      "Available models:\n",
      "- Logistic Regression\n",
      "- Decision Tree\n",
      "- Random Forest\n",
      "- XGBoost\n",
      "- Gradient Boosting\n",
      "- K-Nearest Neighbors\n",
      "- Neural Network (MLP)\n",
      "- Naive Bayes\n",
      "- AdaBoost\n",
      "\n",
      "Total models: 9\n"
     ]
    }
   ],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"Class to manage multiple classification models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def add_model(self, model: BaseSentimentClassifier):\n",
    "        \"\"\"Add a model to the manager\"\"\"\n",
    "        self.models[model.model_name] = model\n",
    "    \n",
    "    def add_all_models(self, random_state: int = 42):\n",
    "        \"\"\"Add all available models\"\"\"\n",
    "        models = [\n",
    "            LogisticRegressionClassifier(random_state),\n",
    "            DecisionTreeSentimentClassifier(random_state),\n",
    "            RandomForestSentimentClassifier(random_state),\n",
    "            XGBoostSentimentClassifier(random_state),\n",
    "            GradientBoostingSentimentClassifier(random_state),\n",
    "            KNNSentimentClassifier(),\n",
    "            MLPSentimentClassifier(random_state),\n",
    "            NaiveBayesClassifier(),\n",
    "            AdaBoostSentimentClassifier(random_state)\n",
    "        ]\n",
    "        \n",
    "        for model in models:\n",
    "            self.add_model(model)\n",
    "    \n",
    "    def train_all_models(self, X_train: np.ndarray, y_train: np.ndarray, \n",
    "                        use_hyperparameter_tuning: bool = False):\n",
    "        \"\"\"Train all models\"\"\"\n",
    "        print(\"Training all models...\")\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            if use_hyperparameter_tuning:\n",
    "                result = model.hyperparameter_tuning(X_train, y_train)\n",
    "                print(f\"Best parameters for {name}: {result['best_params']}\")\n",
    "                print(f\"Best CV score: {result['best_score']:.4f}\")\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                cv_result = model.cross_validate(X_train, y_train)\n",
    "                print(f\"CV score for {name}: {cv_result['mean_score']:.4f} (+/- {cv_result['std_score']:.4f})\")\n",
    "    \n",
    "    def evaluate_all_models(self, evaluator: ModelEvaluator, X_test: np.ndarray, y_test: np.ndarray):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        print(\"\\nEvaluating all models...\")\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if model.is_fitted:\n",
    "                result = evaluator.evaluate_model(model, X_test, y_test, name)\n",
    "                print(f\"\\n{name} - Test Accuracy: {result['accuracy']:.4f}\")\n",
    "    \n",
    "    def get_best_model(self, evaluator: ModelEvaluator) -> Tuple[str, BaseSentimentClassifier]:\n",
    "        \"\"\"Get the best performing model\"\"\"\n",
    "        if not evaluator.results:\n",
    "            raise ValueError(\"No models have been evaluated yet\")\n",
    "        \n",
    "        best_model_name = max(evaluator.results.keys(), \n",
    "                            key=lambda x: evaluator.results[x]['accuracy'])\n",
    "        \n",
    "        return best_model_name, self.models[best_model_name]\n",
    "    \n",
    "    def save_all_models(self, directory: str = \"saved_models\"):\n",
    "        \"\"\"Save all trained models\"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if model.is_fitted:\n",
    "                filepath = os.path.join(directory, f\"{name.replace(' ', '_').lower()}_model.pkl\")\n",
    "                model.save_model(filepath)\n",
    "                print(f\"Saved {name} to {filepath}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Classification models setup complete!\")\n",
    "    print(\"\\nAvailable models:\")\n",
    "    \n",
    "    # Create model manager and add all models\n",
    "    manager = ModelManager()\n",
    "    manager.add_all_models()\n",
    "    \n",
    "    for model_name in manager.models.keys():\n",
    "        print(f\"- {model_name}\")\n",
    "    \n",
    "    print(f\"\\nTotal models: {len(manager.models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4955b07",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering\n",
    "\n",
    "## Class Overview\n",
    "\n",
    "The `AdvancedFeatureEngineer` class provides sophisticated feature engineering techniques to enhance model performance by creating additional informative features from existing data.\n",
    "\n",
    "### Key Capabilities\n",
    "- Feature interactions (multiplicative combinations)\n",
    "- Polynomial feature expansion\n",
    "- Statistical feature generation\n",
    "- Memory-efficient implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffdf16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced feature engineering class\n",
    "class AdvancedFeatureEngineer:\n",
    "    \"\"\"Advanced feature engineering techniques\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_combinations = []\n",
    "    \n",
    "    def create_feature_interactions(self, X: np.ndarray, top_features: int = 100) -> np.ndarray:\n",
    "        \"\"\"Create feature interactions\"\"\"\n",
    "        # Select top features based on variance\n",
    "        feature_vars = np.var(X, axis=0)\n",
    "        top_indices = np.argsort(feature_vars)[-top_features:]\n",
    "        \n",
    "        X_top = X[:, top_indices]\n",
    "        \n",
    "        # Create pairwise interactions\n",
    "        interactions = []\n",
    "        for i in range(X_top.shape[1]):\n",
    "            for j in range(i+1, X_top.shape[1]):\n",
    "                interaction = X_top[:, i] * X_top[:, j]\n",
    "                interactions.append(interaction.reshape(-1, 1))\n",
    "        \n",
    "        if interactions:\n",
    "            X_interactions = np.hstack(interactions)\n",
    "            return np.hstack([X, X_interactions])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def create_polynomial_features(self, X: np.ndarray, degree: int = 2, \n",
    "                                 max_features: int = 1000) -> np.ndarray:\n",
    "        \"\"\"Create polynomial features\"\"\"\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        \n",
    "        # Limit features to avoid memory issues\n",
    "        if X.shape[1] > max_features:\n",
    "            X = X[:, :max_features]\n",
    "        \n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        \n",
    "        return X_poly\n",
    "    \n",
    "    def create_statistical_features(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Create statistical features\"\"\"\n",
    "        # Row-wise statistics\n",
    "        row_mean = np.mean(X, axis=1).reshape(-1, 1)\n",
    "        row_std = np.std(X, axis=1).reshape(-1, 1)\n",
    "        row_max = np.max(X, axis=1).reshape(-1, 1)\n",
    "        row_min = np.min(X, axis=1).reshape(-1, 1)\n",
    "        row_median = np.median(X, axis=1).reshape(-1, 1)\n",
    "        \n",
    "        statistical_features = np.hstack([\n",
    "            row_mean, row_std, row_max, row_min, row_median\n",
    "        ])\n",
    "        \n",
    "        return np.hstack([X, statistical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db9bc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced feature engineering available:\n",
      "- Feature interactions\n",
      "- Polynomial features\n",
      "- Statistical features\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Advanced feature engineering available:\")\n",
    "    print(\"- Feature interactions\")\n",
    "    print(\"- Polynomial features\")\n",
    "    print(\"- Statistical features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aeb079",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analysis Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "A complete, configurable pipeline for training and evaluating machine learning models on tweet sentiment data. The pipeline handles:\n",
    "\n",
    "1. Data loading and preprocessing\n",
    "2. Feature extraction and engineering\n",
    "3. Model training and evaluation\n",
    "4. Results analysis and visualization\n",
    "5. Model persistence and prediction\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### Core Modules\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| `BaseDataProcessor` | Handles data cleaning and label encoding |\n",
    "| `FeatureExtractor` | Transforms text into numerical features |\n",
    "| `DataSplitter` | Splits data into train/validation/test sets |\n",
    "| `ModelManager` | Manages multiple classifier models |\n",
    "| `ModelEvaluator` | Evaluates and compares model performance |\n",
    "\n",
    "### Supported Models\n",
    "1. Logistic Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "5. Gradient Boosting\n",
    "6. K-Nearest Neighbors\n",
    "7. Multilayer Perceptron (Neural Network)\n",
    "8. Naive Bayes\n",
    "9. AdaBoost\n",
    "\n",
    "## Pipeline Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Raw Data] --> B[Preprocessing]\n",
    "    B --> C[Feature Extraction]\n",
    "    C --> D[Train/Test Split]\n",
    "    D --> E[Model Training]\n",
    "    E --> F[Evaluation]\n",
    "    F --> G[Results Analysis]\n",
    "    G --> H[Prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef793e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetSentimentPipeline:\n",
    "    \"\"\"Complete pipeline for tweet sentiment analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = None, data_df: pd.DataFrame = None):\n",
    "        self.data_path = data_path\n",
    "        self.data_df = data_df\n",
    "        \n",
    "        # Initialize components\n",
    "        self.data_processor = BaseDataProcessor()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.data_splitter = DataSplitter()\n",
    "        self.evaluator = ModelEvaluator()\n",
    "        self.model_manager = ModelManager()\n",
    "        self.feature_engineer = AdvancedFeatureEngineer()\n",
    "        \n",
    "        # Data storage\n",
    "        self.df_clean = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        self.label_mapping = None\n",
    "        \n",
    "        # Results\n",
    "        self.results_summary = {}\n",
    "    \n",
    "    def load_and_preprocess_data(self, use_advanced_features: bool = False):\n",
    "        \"\"\"Load and preprocess the data\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Load data\n",
    "        if self.data_df is not None:\n",
    "            df = self.data_df.copy()\n",
    "        else:\n",
    "            df = pd.read_csv(self.data_path)\n",
    "        \n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        self.df_clean = self.data_processor.preprocess_data(df)\n",
    "        print(f\"Clean data shape: {self.df_clean.shape}\")\n",
    "        \n",
    "        # Display sentiment distribution\n",
    "        print(\"\\nSentiment distribution:\")\n",
    "        print(self.df_clean['sentiment'].value_counts())\n",
    "        \n",
    "        # Encode labels\n",
    "        y = self.data_processor.encode_labels(self.df_clean['sentiment'])\n",
    "        self.label_mapping = self.data_processor.get_label_mapping()\n",
    "        print(f\"\\nLabel mapping: {self.label_mapping}\")\n",
    "        \n",
    "        # Extract features\n",
    "        print(\"\\nExtracting features...\")\n",
    "        X_train_base, X_test_base = self.feature_extractor.fit_transform_features(\n",
    "            self.df_clean['processed_tweet']\n",
    "        )\n",
    "        \n",
    "        if X_test_base is None:\n",
    "            X_features = X_train_base\n",
    "        else:\n",
    "            X_features = np.vstack([X_train_base, X_test_base])\n",
    "        \n",
    "        print(f\"Feature matrix shape: {X_features.shape}\")\n",
    "        \n",
    "        # Advanced feature engineering\n",
    "        if use_advanced_features:\n",
    "            print(\"Applying advanced feature engineering...\")\n",
    "            \n",
    "            # Create feature interactions\n",
    "            X_features = self.feature_engineer.create_feature_interactions(X_features)\n",
    "            print(f\"After interactions: {X_features.shape}\")\n",
    "            \n",
    "            # Create statistical features\n",
    "            X_features = self.feature_engineer.create_statistical_features(X_features)\n",
    "            print(f\"After statistical features: {X_features.shape}\")\n",
    "        \n",
    "        # Split data\n",
    "        print(\"\\nSplitting data...\")\n",
    "        self.X_train, self.X_val, self.X_test, self.y_train, self.y_val, self.y_test = \\\n",
    "            self.data_splitter.split_data(X_features, y)\n",
    "        \n",
    "        print(f\"Train set: {self.X_train.shape}\")\n",
    "        print(f\"Validation set: {self.X_val.shape}\")\n",
    "        print(f\"Test set: {self.X_test.shape}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def train_individual_models(self, use_hyperparameter_tuning: bool = False):\n",
    "        \"\"\"Train individual classification models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING INDIVIDUAL MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Add all models to manager\n",
    "        self.model_manager.add_all_models()\n",
    "        \n",
    "        # Train all models\n",
    "        self.model_manager.train_all_models(\n",
    "            self.X_train, self.y_train, \n",
    "            use_hyperparameter_tuning=use_hyperparameter_tuning\n",
    "        )\n",
    "        \n",
    "        # Evaluate all models\n",
    "        self.model_manager.evaluate_all_models(\n",
    "            self.evaluator, self.X_test, self.y_test\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def analyze_results(self):\n",
    "        \"\"\"Analyze and visualize results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RESULTS ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Get comparison of all models\n",
    "        comparison = self.evaluator.compare_models()\n",
    "        print(\"\\nModel Performance Comparison:\")\n",
    "        print(comparison)\n",
    "        \n",
    "        # Plot comparison\n",
    "        self.evaluator.plot_model_comparison()\n",
    "        \n",
    "        # Get best model\n",
    "        best_model_name, best_model = self.model_manager.get_best_model(self.evaluator)\n",
    "        print(f\"\\nBest Model: {best_model_name}\")\n",
    "        print(f\"Best Accuracy: {self.evaluator.results[best_model_name]['accuracy']:.4f}\")\n",
    "        \n",
    "        # Detailed analysis of best model\n",
    "        print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
    "        print(self.evaluator.results[best_model_name]['classification_report'])\n",
    "        \n",
    "        # Plot confusion matrix for best model\n",
    "        label_names = [self.label_mapping[i] for i in sorted(self.label_mapping.keys())]\n",
    "        self.evaluator.plot_confusion_matrix(best_model_name, label_names)\n",
    "        \n",
    "        # Feature importance analysis\n",
    "        try:\n",
    "            feature_importance = self.feature_extractor.get_feature_importance(best_model, top_n=15)\n",
    "            print(f\"\\nTop 15 Features for {best_model_name}:\")\n",
    "            print(feature_importance)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "            plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title(f'Top Features - {best_model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze feature importance: {str(e)}\")\n",
    "        \n",
    "        # Store results summary\n",
    "        self.results_summary = {\n",
    "            'best_model': best_model_name,\n",
    "            'best_accuracy': self.evaluator.results[best_model_name]['accuracy'],\n",
    "            'all_results': comparison,\n",
    "            'label_mapping': self.label_mapping\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_new_samples(self, texts: List[str], model_name: str = None):\n",
    "        \"\"\"Predict sentiment for new text samples\"\"\"\n",
    "        if model_name is None:\n",
    "            model_name = self.results_summary['best_model']\n",
    "        \n",
    "        # Get the model\n",
    "        if model_name in self.model_manager.models:\n",
    "            model = self.model_manager.models[model_name]\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not found\")\n",
    "        \n",
    "        # Preprocess texts (basic preprocessing)\n",
    "        processed_texts = [text.lower().strip() for text in texts]\n",
    "        \n",
    "        # Transform features\n",
    "        X_new = self.feature_extractor.vectorizer.transform(processed_texts).toarray()\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_new)\n",
    "        probabilities = model.predict_proba(X_new)\n",
    "        \n",
    "        # Convert predictions to labels\n",
    "        predicted_labels = [self.label_mapping[pred] for pred in predictions]\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results_df = pd.DataFrame({\n",
    "            'text': texts,\n",
    "            'predicted_sentiment': predicted_labels,\n",
    "            'confidence': np.max(probabilities, axis=1)\n",
    "        })\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def save_models(self, directory: str = \"saved_models\"):\n",
    "        \"\"\"Save all trained models\"\"\"\n",
    "        print(f\"\\nSaving models to {directory}...\")\n",
    "        self.model_manager.save_all_models(directory)\n",
    "        \n",
    "        # Save feature extractor\n",
    "        import joblib\n",
    "        joblib.dump(self.feature_extractor, f\"{directory}/feature_extractor.pkl\")\n",
    "        joblib.dump(self.data_processor, f\"{directory}/data_processor.pkl\")\n",
    "        \n",
    "        print(\"All models saved successfully!\")\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"COMPREHENSIVE SENTIMENT ANALYSIS REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nDataset Information:\")\n",
    "        print(f\"- Total samples: {len(self.df_clean)}\")\n",
    "        print(f\"- Features: {self.X_train.shape[1]}\")\n",
    "        print(f\"- Classes: {len(self.label_mapping)}\")\n",
    "        \n",
    "        print(f\"\\nClass Distribution:\")\n",
    "        for label, count in self.df_clean['sentiment'].value_counts().items():\n",
    "            print(f\"- {label}: {count} ({count/len(self.df_clean)*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nModel Performance Summary:\")\n",
    "        comparison = self.evaluator.compare_models()\n",
    "        for _, row in comparison.iterrows():\n",
    "            print(f\"- {row['Model']}: {row['Accuracy']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nBest Model: {self.results_summary['best_model']}\")\n",
    "        print(f\"Best Accuracy: {self.results_summary['best_accuracy']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nRecommendations:\")\n",
    "        if self.results_summary['best_accuracy'] > 0.85:\n",
    "            print(\"- Excellent performance! Model is ready for production.\")\n",
    "        elif self.results_summary['best_accuracy'] > 0.75:\n",
    "            print(\"- Good performance. Consider more data or feature engineering.\")\n",
    "        else:\n",
    "            print(\"- Performance needs improvement. Consider:\")\n",
    "            print(\"  * More training data\")\n",
    "            print(\"  * Better feature engineering\")\n",
    "            print(\"  * Different preprocessing approaches\")\n",
    "            print(\"  * Advanced deep learning models\")\n",
    "\n",
    "def run_complete_pipeline(data_df: pd.DataFrame, use_advanced_features: bool = False,\n",
    "                         use_hyperparameter_tuning: bool = False):\n",
    "    \"\"\"Run the complete sentiment analysis pipeline.\"\"\"\n",
    "    \n",
    "    pipeline = TweetSentimentPipeline(data_df=data_df)\n",
    "    \n",
    "    # Step 1: Preprocess data and extract features\n",
    "    pipeline.load_and_preprocess_data(use_advanced_features=use_advanced_features)\n",
    "    \n",
    "    # Step 2: Train individual models\n",
    "    pipeline.train_individual_models(use_hyperparameter_tuning=use_hyperparameter_tuning)\n",
    "    \n",
    "    # Step 3: Analyze model results and visualize\n",
    "    pipeline.analyze_results()\n",
    "    \n",
    "    # Step 4 (Optional): Save trained models\n",
    "    pipeline.save_models()\n",
    "    \n",
    "    # Step 5 (Optional): Generate a report\n",
    "    pipeline.generate_report()\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b5ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the minimal pipeline\n",
    "# sample_df = cleaned_tweets_df.sample(frac=0.3, random_state=42)\n",
    "# pipeline = run_minimal_pipeline(data_df=sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f576cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Original data shape: (9070, 5)\n",
      "Columns: ['tweet', 'product', 'tokens', 'processed_tweet', 'sentiment']\n",
      "Clean data shape: (9068, 5)\n",
      "\n",
      "Sentiment distribution:\n",
      "No emotion toward brand or product    5373\n",
      "Positive emotion                      2970\n",
      "Negative emotion                       569\n",
      "I can't tell                           156\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Label mapping: {0: \"I can't tell\", 1: 'Negative emotion', 2: 'No emotion toward brand or product', 3: 'Positive emotion'}\n",
      "\n",
      "Extracting features...\n",
      "Feature matrix shape: (9068, 1000)\n",
      "Applying advanced feature engineering...\n",
      "After interactions: (9068, 5950)\n",
      "After statistical features: (9068, 5955)\n",
      "\n",
      "Splitting data...\n",
      "Train set: (5440, 5955)\n",
      "Validation set: (1814, 5955)\n",
      "Test set: (1814, 5955)\n",
      "\n",
      "==================================================\n",
      "TRAINING INDIVIDUAL MODELS\n",
      "==================================================\n",
      "Training all models...\n",
      "\n",
      "Training Logistic Regression...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Complete Sentiment Analysis Pipeline Execution\n",
    "\n",
    "# Pipeline Initialization\n",
    "\n",
    "pipeline = run_complete_pipeline(data_df=cleaned_tweets_df,\n",
    "                                 use_advanced_features=True,\n",
    "                                 use_hyperparameter_tuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5eaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluatorF1:\n",
    "    \"\"\"\n",
    "    Enhanced model evaluator with F1 score optimization for sentiment analysis.\n",
    "    \n",
    "    Features:\n",
    "    - Primary focus on macro-averaged F1 score\n",
    "    - Detailed per-class metrics\n",
    "    - Comprehensive visualization tools\n",
    "    - Model comparison functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with empty results storage\"\"\"\n",
    "        self.results = {}\n",
    "    \n",
    "    def evaluate_model(self, model, X_test: np.ndarray, y_test: np.ndarray, \n",
    "                      model_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate model performance with F1 focus.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained classifier\n",
    "            X_test: Test features\n",
    "            y_test: True labels\n",
    "            model_name: Identifier for the model\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing:\n",
    "            - f1_macro: Macro-averaged F1 score\n",
    "            - f1_weighted: Weighted F1 score\n",
    "            - accuracy: Overall accuracy\n",
    "            - class_report: Full classification report\n",
    "            - cm: Confusion matrix\n",
    "            - predictions: Model predictions\n",
    "        \"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'accuracy': accuracy,\n",
    "            'class_report': class_report,\n",
    "            'cm': cm,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        self.results[model_name] = results\n",
    "        return results\n",
    "    \n",
    "    def plot_confusion_matrix(self, model_name: str, class_names: List[str] = None,\n",
    "                            figsize: Tuple[int, int] = (8, 6)):\n",
    "        \"\"\"\n",
    "        Visualize confusion matrix with enhanced formatting.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of model to visualize\n",
    "            class_names: List of class names for labeling\n",
    "            figsize: Figure dimensions\n",
    "        \"\"\"\n",
    "        if model_name not in self.results:\n",
    "            raise ValueError(f\"Model {model_name} not found in results\")\n",
    "        \n",
    "        cm = self.results[model_name]['cm']\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=class_names, \n",
    "                   yticklabels=class_names,\n",
    "                   cbar=False)\n",
    "        plt.title(f'Confusion Matrix - {model_name}', pad=20)\n",
    "        plt.xlabel('Predicted Label', labelpad=15)\n",
    "        plt.ylabel('True Label', labelpad=15)\n",
    "        plt.xticks(rotation=45 if len(class_names) > 3 else 0)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def compare_models(self, metric: str = 'f1_macro') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compare model performance on specified metric.\n",
    "        \n",
    "        Args:\n",
    "            metric: Metric to compare ('f1_macro', 'f1_weighted', 'accuracy')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame sorted by metric score\n",
    "        \"\"\"\n",
    "        valid_metrics = ['f1_macro', 'f1_weighted', 'accuracy']\n",
    "        if metric not in valid_metrics:\n",
    "            raise ValueError(f\"Metric must be one of {valid_metrics}\")\n",
    "            \n",
    "        comparison = pd.DataFrame([\n",
    "            {\n",
    "                'Model': name,\n",
    "                'F1 Macro': results['f1_macro'],\n",
    "                'F1 Weighted': results['f1_weighted'],\n",
    "                'Accuracy': results['accuracy']\n",
    "            }\n",
    "            for name, results in self.results.items()\n",
    "        ]).sort_values(metric, ascending=False)\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def plot_metric_comparison(self, metric: str = 'f1_macro', \n",
    "                             figsize: Tuple[int, int] = (10, 6)):\n",
    "        \"\"\"\n",
    "        Visualize model comparison for specified metric.\n",
    "        \n",
    "        Args:\n",
    "            metric: Metric to visualize\n",
    "            figsize: Figure dimensions\n",
    "        \"\"\"\n",
    "        comparison = self.compare_models(metric)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        bars = plt.bar(comparison['Model'], comparison[metric], \n",
    "                      color=plt.cm.Blues(np.linspace(0.4, 1, len(comparison))))\n",
    "        \n",
    "        plt.title(f'Model Comparison - {metric.replace(\"_\", \" \").title()}', pad=20)\n",
    "        plt.xlabel('Model', labelpad=15)\n",
    "        plt.ylabel(metric.replace(\"_\", \" \").title(), labelpad=15)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}', \n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def get_best_model(self, metric: str = 'f1_macro') -> Tuple[str, Dict]:\n",
    "        \"\"\"\n",
    "        Identify best performing model based on specified metric.\n",
    "        \n",
    "        Args:\n",
    "            metric: Metric to optimize for\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (model_name, results_dict)\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No models have been evaluated yet\")\n",
    "            \n",
    "        best_model = max(self.results.items(), \n",
    "                        key=lambda x: x[1][metric])\n",
    "        return best_model\n",
    "    \n",
    "    def generate_report(self, model_name: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate comprehensive evaluation report.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Specific model to report on (None for all)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing:\n",
    "            - model_name: Performance metrics\n",
    "            - best_model: Best performing model info\n",
    "            - comparison: All models comparison\n",
    "        \"\"\"\n",
    "        if model_name:\n",
    "            if model_name not in self.results:\n",
    "                raise ValueError(f\"Model {model_name} not found\")\n",
    "            return {model_name: self.results[model_name]}\n",
    "        \n",
    "        best_name, best_results = self.get_best_model()\n",
    "        return {\n",
    "            'best_model': {\n",
    "                'name': best_name,\n",
    "                'f1_macro': best_results['f1_macro'],\n",
    "                'accuracy': best_results['accuracy']\n",
    "            },\n",
    "            'comparison': self.compare_models().to_dict('records'),\n",
    "            'all_results': self.results\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f337a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManagerF1:\n",
    "    \"\"\"\n",
    "    Enhanced model manager focused on F1 score optimization for sentiment analysis.\n",
    "    \n",
    "    Features:\n",
    "    - F1-centric model training and evaluation\n",
    "    - Comprehensive model tracking\n",
    "    - Hyperparameter tuning with F1 optimization\n",
    "    - Model persistence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize model and results storage\"\"\"\n",
    "        self.models: Dict[str, BaseEstimator] = {}\n",
    "        self.training_results: Dict[str, Any] = {}\n",
    "    \n",
    "    def add_model(self, model: BaseEstimator) -> None:\n",
    "        \"\"\"\n",
    "        Add a model to the manager.\n",
    "        \n",
    "        Args:\n",
    "            model: Initialized model object implementing scikit-learn interface\n",
    "        \"\"\"\n",
    "        if not hasattr(model, 'model_name'):\n",
    "            raise ValueError(\"Model must have 'model_name' attribute\")\n",
    "        self.models[model.model_name] = model\n",
    "    \n",
    "    def add_all_models(self, random_state: int = 42) -> None:\n",
    "        \"\"\"\n",
    "        Add all available models with F1-optimized defaults.\n",
    "        \n",
    "        Args:\n",
    "            random_state: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        models = [\n",
    "            NaiveBayesClassifier(),\n",
    "            LogisticRegressionClassifier(random_state, class_weight='balanced'),\n",
    "            RandomForestSentimentClassifier(random_state, class_weight='balanced_subsample')\n",
    "        ]\n",
    "        \n",
    "        for model in models:\n",
    "            self.add_model(model)\n",
    "    \n",
    "    def train_all_models(self, \n",
    "                        X_train: np.ndarray, \n",
    "                        y_train: np.ndarray,\n",
    "                        use_hyperparameter_tuning: bool = False,\n",
    "                        scoring: str = 'f1_macro',\n",
    "                        cv: int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Train all models with F1 optimization focus.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training labels\n",
    "            use_hyperparameter_tuning: Whether to perform grid search\n",
    "            scoring: Metric to optimize (default: 'f1_macro')\n",
    "            cv: Cross-validation folds\n",
    "        \"\"\"\n",
    "        print(f\"\\nTraining models with {scoring} optimization...\")\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\n=== Training {name} ===\")\n",
    "            \n",
    "            if use_hyperparameter_tuning:\n",
    "                result = model.hyperparameter_tuning(\n",
    "                    X_train, y_train,\n",
    "                    scoring=scoring,\n",
    "                    cv=cv\n",
    "                )\n",
    "                self.training_results[name] = result\n",
    "                print(f\"Best params: {result['best_params']}\")\n",
    "                print(f\"Best {scoring}: {result['best_score']:.4f}\")\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X_train, y_train,\n",
    "                    scoring=scoring,\n",
    "                    cv=cv\n",
    "                )\n",
    "                self.training_results[name] = {\n",
    "                    'mean_score': np.mean(cv_scores),\n",
    "                    'std_score': np.std(cv_scores)\n",
    "                }\n",
    "                print(f\"CV {scoring}: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
    "    \n",
    "    def evaluate_all_models(self,\n",
    "                          evaluator: ModelEvaluatorF1,\n",
    "                          X_test: np.ndarray,\n",
    "                          y_test: np.ndarray,\n",
    "                          metric: str = 'f1_macro') -> None:\n",
    "        \"\"\"\n",
    "        Evaluate all trained models using F1-focused evaluator.\n",
    "        \n",
    "        Args:\n",
    "            evaluator: Initialized ModelEvaluatorF1 instance\n",
    "            X_test: Test features\n",
    "            y_test: Test labels\n",
    "            metric: Primary metric to highlight\n",
    "        \"\"\"\n",
    "        print(f\"\\nEvaluating models on {metric}...\")\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if hasattr(model, 'is_fitted') and model.is_fitted:\n",
    "                result = evaluator.evaluate_model(model, X_test, y_test, name)\n",
    "                print(f\"{name}:\")\n",
    "                print(f\"- {metric}: {result[metric]:.4f}\")\n",
    "                print(f\"- Accuracy: {result['accuracy']:.4f}\")\n",
    "    \n",
    "    def get_best_model(self,\n",
    "                      evaluator: ModelEvaluatorF1,\n",
    "                      metric: str = 'f1_macro'):\n",
    "        \"\"\"\n",
    "        Get the best performing model based on specified metric.\n",
    "        \n",
    "        Args:\n",
    "            evaluator: ModelEvaluatorF1 with evaluation results\n",
    "            metric: Metric to optimize for\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (model_name, model_instance)\n",
    "        \"\"\" \n",
    "        best_name = max(evaluator.results.items(),\n",
    "                       key=lambda x: x[1][metric])[0]\n",
    "        return best_name, self.models[best_name]\n",
    "    \n",
    "    def save_all_models(self,\n",
    "                       directory: str = \"saved_models\",\n",
    "                       save_format: str = 'joblib') -> None:\n",
    "        \"\"\"\n",
    "        Save all trained models to disk.\n",
    "        \n",
    "        Args:\n",
    "            directory: Output directory path\n",
    "            save_format: Either 'joblib' or 'pickle'\n",
    "        \"\"\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            if hasattr(model, 'is_fitted') and model.is_fitted:\n",
    "                filename = f\"{name.lower().replace(' ', '_')}.{save_format}\"\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                \n",
    "                if save_format == 'joblib':\n",
    "                    import joblib\n",
    "                    joblib.dump(model, filepath)\n",
    "                else:\n",
    "                    import pickle\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        pickle.dump(model, f)\n",
    "                \n",
    "                print(f\"Saved {name} to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d551ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetSentimentPipelineF1:\n",
    "    \"\"\"\n",
    "    Complete F1-optimized pipeline for tweet sentiment analysis.\n",
    "    \n",
    "    Features:\n",
    "    - F1 score as primary optimization metric\n",
    "    - Comprehensive model training and evaluation\n",
    "    - Advanced feature engineering\n",
    "    - Model persistence\n",
    "    - Detailed reporting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = None, data_df: pd.DataFrame = None):\n",
    "        \"\"\"\n",
    "        Initialize pipeline components.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to raw data file\n",
    "            data_df: Preloaded DataFrame (alternative to data_path)\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.data_df = data_df\n",
    "        \n",
    "        # Initialize components\n",
    "        self.data_processor = BaseDataProcessor()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.data_splitter = DataSplitter()\n",
    "        self.evaluator = ModelEvaluatorF1()\n",
    "        self.model_manager = ModelManagerF1()\n",
    "        self.feature_engineer = AdvancedFeatureEngineer()\n",
    "        \n",
    "        # Configuration\n",
    "        self.scoring_metric = 'f1_macro'  # Primary optimization metric\n",
    "        \n",
    "        # Data storage\n",
    "        self.df_clean = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        self.label_mapping = None\n",
    "        \n",
    "        # Results\n",
    "        self.results_summary = {}\n",
    "    \n",
    "    def load_and_preprocess_data(self, use_advanced_features: bool = False) -> 'TweetSentimentPipelineF1':\n",
    "        \"\"\"\n",
    "        Load and preprocess the data with optional advanced features.\n",
    "        \n",
    "        Args:\n",
    "            use_advanced_features: Whether to generate additional features\n",
    "            \n",
    "        Returns:\n",
    "            self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Load data\n",
    "        df = self.data_df.copy() if self.data_df is not None else pd.read_csv(self.data_path)\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        self.df_clean = self.data_processor.preprocess_data(df)\n",
    "        print(f\"Clean data shape: {self.df_clean.shape}\")\n",
    "        print(\"\\nSentiment distribution:\")\n",
    "        print(self.df_clean['sentiment'].value_counts())\n",
    "        \n",
    "        # Encode labels\n",
    "        y = self.data_processor.encode_labels(self.df_clean['sentiment'])\n",
    "        self.label_mapping = self.data_processor.get_label_mapping()\n",
    "        print(f\"\\nLabel mapping: {self.label_mapping}\")\n",
    "        \n",
    "        # Extract features\n",
    "        print(\"\\nExtracting features...\")\n",
    "        X_train_base, X_test_base = self.feature_extractor.fit_transform_features(\n",
    "            self.df_clean['processed_tweet']\n",
    "        )\n",
    "        X_features = X_train_base if X_test_base is None else np.vstack([X_train_base, X_test_base])\n",
    "        print(f\"Feature matrix shape: {X_features.shape}\")\n",
    "        \n",
    "        # Advanced feature engineering\n",
    "        if use_advanced_features:\n",
    "            print(\"Applying advanced feature engineering...\")\n",
    "            X_features = self.feature_engineer.create_feature_interactions(X_features)\n",
    "            X_features = self.feature_engineer.create_statistical_features(X_features)\n",
    "            print(f\"Final feature shape: {X_features.shape}\")\n",
    "        \n",
    "        # Split data\n",
    "        print(\"\\nSplitting data...\")\n",
    "        (self.X_train, self.X_val, self.X_test, \n",
    "         self.y_train, self.y_val, self.y_test) = self.data_splitter.split_data(X_features, y)\n",
    "        \n",
    "        print(f\"Train: {self.X_train.shape}, Val: {self.X_val.shape}, Test: {self.X_test.shape}\")\n",
    "        return self\n",
    "    \n",
    "    def train_individual_models(self, use_hyperparameter_tuning: bool = False) -> 'TweetSentimentPipelineF1':\n",
    "        \"\"\"\n",
    "        Train all models with F1 optimization.\n",
    "        \n",
    "        Args:\n",
    "            use_hyperparameter_tuning: Whether to perform grid search\n",
    "            \n",
    "        Returns:\n",
    "            self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING MODELS (F1-OPTIMIZED)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        self.model_manager.add_all_models()\n",
    "        self.model_manager.train_all_models(\n",
    "            self.X_train, self.y_train,\n",
    "            use_hyperparameter_tuning=use_hyperparameter_tuning,\n",
    "            scoring=self.scoring_metric\n",
    "        )\n",
    "        \n",
    "        self.model_manager.evaluate_all_models(\n",
    "            self.evaluator, self.X_test, self.y_test\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def analyze_results(self) -> 'TweetSentimentPipelineF1':\n",
    "        \"\"\"\n",
    "        Analyze and visualize results with F1 focus.\n",
    "        \n",
    "        Returns:\n",
    "            self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"F1-CENTRIC RESULTS ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # F1-based comparison\n",
    "        comparison = self.evaluator.compare_models(metric='f1_macro')\n",
    "        print(\"\\nModel Performance Comparison (F1 Scores):\")\n",
    "        print(comparison)\n",
    "        \n",
    "        # Visualization\n",
    "        self.evaluator.plot_metric_comparison(metric='f1_macro')\n",
    "        \n",
    "        # Best model analysis\n",
    "        best_name, best_model = self.model_manager.get_best_model(\n",
    "            self.evaluator, metric='f1_macro'\n",
    "        )\n",
    "        print(f\"\\nBest Model (F1): {best_name}\")\n",
    "        print(f\"Best F1 Score: {self.evaluator.results[best_name]['f1_macro']:.4f}\")\n",
    "        \n",
    "        # Detailed metrics\n",
    "        print(f\"\\nClassification Report for {best_name}:\")\n",
    "        print(self.evaluator.results[best_name]['classification_report'])\n",
    "        \n",
    "        # Confusion matrix\n",
    "        label_names = [self.label_mapping[i] for i in sorted(self.label_mapping.keys())]\n",
    "        self.evaluator.plot_confusion_matrix(best_name, label_names)\n",
    "        \n",
    "        # Feature importance\n",
    "        try:\n",
    "            feat_imp = self.feature_extractor.get_feature_importance(best_model, top_n=15)\n",
    "            print(f\"\\nTop 15 Features for {best_name}:\")\n",
    "            print(feat_imp)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='importance', y='feature', data=feat_imp)\n",
    "            plt.title(f'Feature Importance - {best_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nFeature importance unavailable: {str(e)}\")\n",
    "        \n",
    "        # Store summary\n",
    "        self.results_summary = {\n",
    "            'best_model': best_name,\n",
    "            'best_f1': self.evaluator.results[best_name]['f1_macro'],\n",
    "            'comparison': comparison,\n",
    "            'label_mapping': self.label_mapping\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def predict_new_samples(self, texts: List[str], model_name: str = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Predict sentiment for new text samples.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of raw text strings\n",
    "            model_name: Specific model to use (None for best model)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with predictions and confidence scores\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'results_summary'):\n",
    "            raise ValueError(\"Pipeline not trained - run training first\")\n",
    "            \n",
    "        model_name = model_name or self.results_summary['best_model']\n",
    "        model = self.model_manager.models.get(model_name)\n",
    "        \n",
    "        if model is None:\n",
    "            raise ValueError(f\"Model {model_name} not found\")\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        processed_texts = [text.lower().strip() for text in texts]\n",
    "        X_new = self.feature_extractor.vectorizer.transform(processed_texts)\n",
    "        predictions = model.predict(X_new)\n",
    "        probabilities = model.predict_proba(X_new)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'text': texts,\n",
    "            'predicted_sentiment': [self.label_mapping[p] for p in predictions],\n",
    "            'confidence': np.max(probabilities, axis=1)\n",
    "        })\n",
    "    \n",
    "    def save_models(self, directory: str = \"saved_models\") -> None:\n",
    "        \"\"\"Save all trained models and components to disk\"\"\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"\\nSaving models to {directory}...\")\n",
    "        \n",
    "        self.model_manager.save_all_models(directory)\n",
    "        joblib.dump(self.feature_extractor, f\"{directory}/feature_extractor.pkl\")\n",
    "        joblib.dump(self.data_processor, f\"{directory}/data_processor.pkl\")\n",
    "        \n",
    "        print(\"All components saved successfully!\")\n",
    "    \n",
    "    def generate_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive performance report\"\"\"\n",
    "        report = {\n",
    "            'dataset_info': {\n",
    "                'samples': len(self.df_clean),\n",
    "                'features': self.X_train.shape[1],\n",
    "                'classes': len(self.label_mapping),\n",
    "                'class_distribution': self.df_clean['sentiment'].value_counts().to_dict()\n",
    "            },\n",
    "            'best_model': self.results_summary['best_model'],\n",
    "            'best_f1': self.results_summary['best_f1'],\n",
    "            'model_comparison': self.evaluator.compare_models(metric='f1_macro').to_dict(),\n",
    "            'recommendations': self._generate_recommendations()\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"COMPREHENSIVE PERFORMANCE REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nBest Model: {report['best_model']}\")\n",
    "        print(f\"Best F1 Score: {report['best_f1']:.4f}\")\n",
    "        print(\"\\nRecommendations:\")\n",
    "        for rec in report['recommendations']:\n",
    "            print(f\"- {rec}\")\n",
    "            \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self) -> List[str]:\n",
    "        \"\"\"Generate actionable recommendations based on performance\"\"\"\n",
    "        f1_score = self.results_summary['best_f1']\n",
    "        \n",
    "        if f1_score > 0.85:\n",
    "            return [\n",
    "                \"Excellent performance - ready for production\",\n",
    "                \"Consider monitoring for concept drift\"\n",
    "            ]\n",
    "        elif f1_score > 0.75:\n",
    "            return [\n",
    "                \"Good performance - suitable for deployment\",\n",
    "                \"Try additional feature engineering\",\n",
    "                \"Consider collecting more diverse training data\"\n",
    "            ]\n",
    "        else:\n",
    "            return [\n",
    "                \"Performance needs improvement\",\n",
    "                \"Investigate class imbalance issues\",\n",
    "                \"Try different model architectures\",\n",
    "                \"Review data quality and preprocessing\",\n",
    "                \"Consider ensemble methods\"\n",
    "            ]\n",
    "\n",
    "\n",
    "def run_complete_pipeline_f1(\n",
    "    data_df: pd.DataFrame,\n",
    "    use_advanced_features: bool = False,\n",
    "    use_hyperparameter_tuning: bool = False,\n",
    "    save_models: bool = True\n",
    ") -> TweetSentimentPipelineF1:\n",
    "    \"\"\"\n",
    "    Execute complete F1-optimized sentiment analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        data_df: Input DataFrame containing tweets\n",
    "        use_advanced_features: Whether to generate additional features\n",
    "        use_hyperparameter_tuning: Whether to perform grid search\n",
    "        save_models: Whether to persist trained models\n",
    "        \n",
    "    Returns:\n",
    "        Configured pipeline instance with results\n",
    "    \"\"\"\n",
    "    pipeline = TweetSentimentPipelineF1(data_df=data_df)\n",
    "    \n",
    "    try:\n",
    "        # Data preparation\n",
    "        pipeline.load_and_preprocess_data(use_advanced_features=use_advanced_features)\n",
    "        \n",
    "        # Model training\n",
    "        pipeline.train_individual_models(\n",
    "            use_hyperparameter_tuning=use_hyperparameter_tuning\n",
    "        )\n",
    "        \n",
    "        # Analysis\n",
    "        pipeline.analyze_results()\n",
    "        \n",
    "        # Optional saving\n",
    "        if save_models:\n",
    "            pipeline.save_models()\n",
    "        \n",
    "        # Final report\n",
    "        pipeline.generate_report()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f26eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Sentiment Analysis Pipeline Execution focusing on F1 Score\n",
    "\n",
    "pipeline_f1 = run_complete_pipeline_f1(data_df=cleaned_tweets_df,\n",
    "                                 use_advanced_features=True,\n",
    "                                 use_hyperparameter_tuning=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
